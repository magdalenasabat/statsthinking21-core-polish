---
output:
  pdf_document: default
  bookdown::gitbook:
    lib_dir: "book_assets"
    includes:
      in_header: google_analytics.html
  html_document: default
---
# Wstęp {#wstęp}
```{r echo=FALSE,warning=FALSE,message=FALSE}
library(tidyverse)

```

"Statistical thinking will one day be as necessary for efficient citizenship as the ability to read and write.” - H.G. Wells

## Czym jest rozumowanie statystyczne?

Wnioskowanie statystyczne to sposób rozumienia złożonego świata poprzez opisywanie go za pomocą stosunkowo prostych pojęć, które mimo wszystko oddają istotne aspekty jego struktury lub funkcji, a także dają nam pewne pojęcie o tym, jak bardzo niepewni jesteśmy tych wniosków.  Podstawy rozumowania statystycznego pochodzą przede wszystkim z matematyki i statystyki, ale także z informatyki, psychologii i innych dziedzin nauki.  

Możemy odróżnić wnioskowanie statystyczne od innych form wnioskowania, które mają mniejsze szanse na trafne opisanie świata.  W szczególności, ludzka intuicja często próbuje odpowiedzieć na te same pytania, na które możemy odpowiedzieć używając wnioskowania statystycznego, ale często podsuwa błędną odpowiedź.  Na przykład w ostatnich latach większość Amerykanów podawała, że ich zdaniem przestępczość z użyciem przemocy była gorsza w porównaniu z poprzednim rokiem ([Pew Research Center](http://www.pewresearch.org/fact-tank/2018/01/30/5-facts-about-crime-in-the-u-s/)).  Jednak analiza statystyczna rzeczywistych danych dotyczących przestępczości pokazuje, że w rzeczywistości przestępczość z użyciem przemocy stale *spadała* od lat 90-tych.  Intuicja nas zawodzi, ponieważ polegamy na najlepszych przypuszczeniach (*ang. best guess*) (które psychologowie nazywają *heurystykami*), które często są mylące.  Na przykład, ludzie często oceniają powszechność jakiegoś wydarzenia (np. brutalnej przestępczości) używając *heurystyki dostępności* - to znaczy, jak łatwo możemy przywołać przykład brutalnej przestępczości. Z tego powodu, nasze osądy dotyczące wzrostu przestępczości mogą bardziej odzwierciedlać rosnącą ilość pokrycia tego tematu w mediach, pomimo rzeczywistego spadku przestępczości. Rozumowanie statystyczne dostarcza nam narzędzi do dokładniejszego zrozumienia świata i przezwyciężenia tendencyjności ludzkiego osądu.


## Radzenie sobie z lękiem przed statystyką

Wiele osób przychodzi na swoje pierwsze zajęcia ze statystyki z dużą obawą i niepokojem, zwłaszcza gdy słyszą, że będą musieli nauczyć się kodować, aby analizować dane. Na moich zajęciach przed pierwszą sesją daję studentom ankietę, aby zmierzyć ich stosunek do statystyki, prosząc ich o ocenę kilku stwierdzeń w skali od 1 (zdecydowanie nie zgadzam się) do 7 (zdecydowanie zgadzam się). Jedna z pozycji w ankiecie brzmi: "Myśl o zapisaniu się na kurs statystyki mnie stresuje".  Na ostatnich zajęciach prawie dwie trzecie klasy odpowiedziało piątką lub wyżej, a około jedna czwarta studentów stwierdziła, że zdecydowanie zgadza się z tym stwierdzeniem.  Jeśli więc czujesz się zdenerwowany rozpoczęciem nauki statystyki, nie jesteś sam.

Niepokój jest nieprzyjemnym uczuciem, ale psychologia mówi nam, że ten rodzaj emocjonalnego pobudzenia może pomóc nam *lepiej* wykonywać wiele zadań, poprzez skupienie naszej uwagi. Jeśli więc zaczniesz odczuwać niepokój w związku z materiałem zawartym w tej książce, przypomnij sobie, że wielu innych czytelników czuje się podobnie i że to emocjonalne pobudzenie może w rzeczywistości pomóc ci w lepszym opanowaniu materiału (nawet jeśli na to nie wygląda!).


## Co może zrobić dla nas statystyka?

Są trzy główne rzeczy, które możemy zrobić za pomocą statystyki:

- *Opisać*: Świat jest złożony i często potrzebujemy opisać go w uproszczony sposób, który możemy zrozumieć.  
- *Decydować*: Często musimy podejmować decyzje na podstawie danych, zwykle w obliczu niepewności.
- *Przewidywać*: Często chcemy dokonywać przewidywań dotyczących nowych sytuacji na podstawie naszej wiedzy o poprzednich sytuacjach.

Przyjrzyjmy się ich przykładowi w działaniu, skoncentrowanemu na pytaniu, które interesuje wielu z nas: Jak decydujemy, co jest zdrowe do jedzenia?  Istnieje wiele różnych źródeł wskazówek; rządowe wytyczne dietetyczne, książki o dietach i blogerzy, by wymienić tylko kilka.  Skupmy się na konkretnym pytaniu: Czy tłuszcz nasycony w naszej diecie to coś złego?

Jednym ze sposobów, w jaki możemy odpowiedzieć na to pytanie, jest zdrowy rozsądek.  Jeśli jemy tłuszcz, to zamieni się on prosto w tłuszcz w naszym ciele, prawda? Wszyscy widzieliśmy zdjęcia tętnic zatkanych tłuszczem, więc jedzenie tłuszczu będzie zatykać nasze tętnice, prawda?

Innym sposobem, w jaki możemy odpowiedzieć na to pytanie, jest słuchanie autorytetów. Wytyczne dietetyczne Amerykańskiej Agencji Żywności i Leków (US FDA) jako jedno ze swoich kluczowych zaleceń podają: "Zdrowy sposób odżywiania ogranicza tłuszcze nasycone". Można mieć nadzieję, że te wytyczne będą oparte na dobrej nauce, i w niektórych przypadkach są, ale jak Nina Teicholz nakreśliła w swojej książce "Big Fat Surprise"[@teic:2014], to konkretne zalecenie wydaje się być oparte bardziej na wieloletnim dogmacie badaczy żywienia niż na rzeczywistych dowodach.

Wreszcie, możemy przyjrzeć się samym badaniom naukowym. Zacznijmy od przyjrzenia się dużemu badaniu o nazwie 'PURE study', w którym zbadano diety i wyniki zdrowotne (w tym śmierć) u ponad 135 000 osób z 18 różnych krajów.  W jednej z analiz tej bazy danych (opublikowanej w *The Lancet* w 2017 roku; @dehg:ment:zhan:2017), badacze PURE przedstawili analizę tego, jak spożycie różnych klas makroskładników (w tym tłuszczów nasyconych i węglowodanów) było związane z prawdopodobieństwem śmierci w czasie, gdy ludzie byli śledzeni. Ludzie byli obserwowani przez *medianę* 7,4 roku, co oznacza, że połowa osób w badaniu była obserwowana przez mniej, a połowa przez więcej niż 7,4 roku. Rysunek przedstawia niektóre dane z badania (zaczerpnięte z artykułu), pokazując związek pomiędzy spożyciem tłuszczów nasyconych i węglowodanów a ryzykiem śmierci z jakiejkolwiek przyczyny.

```{r PureDeathSatFat, echo=FALSE,fig.cap="Wykres danych z badania PURE, pokazujący związek między śmiercią z jakiejkolwiek przyczyny a względnym spożyciem tłuszczów nasyconych i węglowodanów.",fig.width=4,fig.height=4,out.height='50%'}

carb_rr <- c(1, 1.07, 1.06, 1.17, 1.28)
satfat_rr <- c(1, 0.96, 0.92, 0.85, 0.86)

df <-
  data.frame(
    quartile = seq(1, 5),
    Carbohydrates = carb_rr,
    SaturatedFat = satfat_rr
  )

df  %>%
  gather(Nutrient, RelativeRisk, -quartile) %>%  # convert to long format
  ggplot(aes(x = quartile, y = RelativeRisk, linetype = Nutrient)) +
  geom_line(size = 1) +
  geom_point(size=2) +
  geom_hline(yintercept = 1,linetype='dashed') +
  theme(legend.position = c(0.2,0.9)) +
  theme(aspect.ratio = 1) +
  labs(
    y = "Relative risk of dying from any cause",
    x = "Quintiles of nutrient intake"
  )
```

Ten wykres jest oparty na dziesięciu liczbach.  Aby uzyskać te liczby, badacze podzielili grupę 135 335 uczestników badania (którą nazywamy "próbą badawczą") na 5 grup ("kwintyli") po uporządkowaniu ich pod względem spożycia któregoś ze składników odżywczych; pierwszy kwintyl zawiera 20% osób z najniższym spożyciem, a piąty kwintyl zawiera 20% z najwyższym spożyciem.  Następnie badacze obliczyli, jak często ludzie w każdej z tych grup umierali w czasie trwania badania (było to badanie podłużne/longitudinalne). Rysunek wyraża to w kategoriach *względnego ryzyka* śmierci w porównaniu z najniższym kwintylem: jeśli liczba ta jest większa od 1, oznacza to, że ludzie w danej grupie są _bardziej_ narażeni na śmierć niż ludzie w najniższym kwintylu, natomiast jeśli jest mniejsza od 1, oznacza to, że ludzie w danej grupie są _mniej_ narażeni na śmierć. Rysunek jest dość jasny: ludzie, którzy jedli więcej tłuszczów nasyconych, mieli *mniejsze* prawdopodobieństwo śmierci podczas badania, przy czym najniższy wskaźnik umieralności zaobserwowano dla ludzi, którzy byli w czwartym kwintylu (czyli jedli więcej tłuszczu niż najniższe 60%, ale mniej niż górne 20%).  Odwrotna sytuacja ma miejsce w przypadku węglowodanów; im więcej węglowodanów jadła dana osoba, tym większe było prawdopodobieństwo jej śmierci podczas badania. Ten przykład pokazuje, jak możemy wykorzystać statystykę do *opisania* złożonego zbioru danych w kategoriach znacznie prostszego zestawu liczb; gdybyśmy musieli spojrzeć na dane od każdego z uczestników badania w tym samym czasie, bylibyśmy przeładowani danymi i trudno byłoby dostrzec wzór, który wyłania się, gdy są one opisane w prostszy sposób.


The numbers in Figure \@ref(fig:PureDeathSatFat) seem to show that deaths decrease with saturated fat and increase with carbohydrate intake, but we also know that there is a lot of uncertainty in the data; there are some people who died early even though they ate a low-carb diet, and, similarly, some people who ate a ton of carbs but lived to a ripe old age.  Given this variability, we want to *decide* whether the relationships that we see in the data are large enough that we wouldn't expect them to occur randomly if there was not truly a relationship between diet and longevity.  Statistics provide us with the tools to make these kinds of decisions, and often people from the outside view this as *the* main purpose of statistics.  But as we will see throughout the book, this need for black-and-white decisions based on fuzzy evidence has often led researchers astray.

Based on the data we would also like to make predictions about future outcomes.  For example, a life insurance company might want to use data about a particular person's intake of fat and carbohydrate to predict how long they are likely to live.  An important aspect of prediction is that it requires us to generalize from the data we already have to some other situation, often in the future; if our conclusions were limited to the specific people in the study at a particular time, then the study would not be very useful.  In general, researchers must assume that their particular sample is representative of a larger *population*, which requires that they obtain the sample in a way that provides an unbiased picture of the population. For example, if the PURE study had recruited all of its participants from religious sects that practice vegetarianism, then we probably wouldn't want to generalize the results to people who follow different dietary standards.

Liczby na rycinie wydają się pokazywać, że liczba zgonów spada wraz z ilością tłuszczów nasyconych i wzrasta wraz z ilością węglowodanów, ale wiemy też, że w danych jest dużo niepewności; są ludzie, którzy zmarli wcześnie, mimo że stosowali dietę niskowęglowodanową i, podobnie, są ludzie, którzy jedli mnóstwo węglowodanów, ale dożyli sędziwego wieku.  Biorąc pod uwagę tę zmienność, chcemy *zdecydować*, czy zależności, które widzimy w danych są na tyle duże, że nie spodziewalibyśmy się ich przypadkowego wystąpienia, gdyby rzeczywiście nie było związku między dietą a długowiecznością.  Statystyka dostarcza nam narzędzi do podejmowania tego rodzaju decyzji i często ludzie z zewnątrz postrzegają to jako *główny* cel statystyki.  Ale jak zobaczymy w całej książce, ta potrzeba czarno-białych decyzji opartych na rozmytych dowodach często prowadziła badaczy na manowce.

Na podstawie danych chcielibyśmy również przewidywać przyszłe wyniki.  Na przykład firma ubezpieczeniowa może chcieć wykorzystać dane o spożyciu tłuszczu i węglowodanów przez konkretną osobę, aby przewidzieć, jak długo prawdopodobnie będzie ona żyła.  Ważnym aspektem przewidywania jest to, że wymaga ono od nas uogólnienia z danych, które już posiadamy, na jakąś inną sytuację, często w przyszłości; gdyby nasze wnioski były ograniczone do konkretnych osób objętych badaniem w danym czasie, wówczas badanie nie byłoby zbyt użyteczne.  Ogólnie rzecz biorąc, badacze muszą założyć, że ich konkretna próba jest reprezentatywna dla większej *populacji*, co wymaga uzyskania próby w sposób zapewniający bezstronny obraz populacji. Na przykład, gdyby badanie PURE rekrutowało wszystkich swoich uczestników z sekt religijnych praktykujących wegetarianizm, to prawdopodobnie nie chcielibyśmy uogólniać wyników na ludzi, którzy stosują inne standardy żywieniowe.


## The big ideas of statistics Wielkie idee statystyki

There are a number of very basic ideas that cut through nearly all aspects of statistical thinking.  Several of these are outlined by @stig in his outstanding book "The Seven Pillars of Statistical Wisdom", which I have augmented here.

### Learning from data

One way to think of statistics is as a set of tools that enable us to learn from data.  In any situation, we start with a set of ideas or *hypotheses* about what might be the case.  In the PURE study, the researchers may have started out with the expectation that eating more fat would lead to higher death rates, given the prevailing negative dogma about saturated fats.  Later in the course we will introduce the idea of *prior knowledge*, which is meant to reflect the knowledge that we bring to a situation.  This prior knowledge can vary in its strength, often based on our amount of experience; if I visit a restaurant for the first time, I am likely to have a weak expectation of how good it will be, but if I visit a restaurant where I have eaten ten times before, my expectations will be much stronger. Similarly, if I look at a restaurant review site and see that a restaurant's average rating of four stars is only based on three reviews, I will have a weaker expectation than I would if it was based on 300 reviews.  

Statistics provides us with a way to describe how new data can be best used to update our beliefs, and in this way there are deep links between statistics and psychology. In fact, many theories of human and animal learning from psychology are closely aligned with ideas from the new field of *machine learning*. Machine learning is a field at the interface of statistics and computer science that focuses on how to build computer algorithms that can learn from experience. While statistics and machine learning often try to solve the same problems, researchers from these fields often take very different approaches; the famous statistician Leo Breiman once referred to them as "The Two Cultures" to reflect how different their approaches can be [@breiman2001]. In this book I will try to blend the two cultures together because both approaches provide useful tools for thinking about data.

Istnieje szereg bardzo podstawowych idei, które przecinają prawie wszystkie aspekty myślenia statystycznego.  Kilka z nich zostało przedstawionych przez @stiga w jego znakomitej książce "The Seven Pillars of Statistical Wisdom", którą tutaj rozszerzyłem.

### Uczenie się z danych

Jednym ze sposobów myślenia o statystyce jest zestaw narzędzi, które pozwalają nam uczyć się z danych.  W każdej sytuacji zaczynamy od zestawu pomysłów lub *hipotez* dotyczących tego, co może się zdarzyć.  W badaniu PURE, naukowcy mogli zacząć od oczekiwania, że spożywanie większej ilości tłuszczu doprowadzi do wyższej śmiertelności, biorąc pod uwagę dominujący negatywny dogmat na temat tłuszczów nasyconych.  W dalszej części kursu wprowadzimy pojęcie *prior knowledge*, które ma odzwierciedlać wiedzę, którą wnosimy do danej sytuacji.  Jeśli odwiedzam restaurację po raz pierwszy, prawdopodobnie będę miał słabe oczekiwania co do jej jakości, ale jeśli odwiedzę restaurację, w której jadłem już dziesięć razy, moje oczekiwania będą znacznie silniejsze. Podobnie, jeśli spojrzę na stronę z recenzjami restauracji i zobaczę, że średnia ocena restauracji na poziomie czterech gwiazdek jest oparta tylko na trzech recenzjach, będę miał słabsze oczekiwania niż gdyby była oparta na 300 recenzjach.  

Statystyka dostarcza nam sposobu na opisanie, jak nowe dane mogą być najlepiej wykorzystane do aktualizacji naszych przekonań i w ten sposób istnieją głębokie powiązania między statystyką a psychologią. W rzeczywistości wiele teorii psychologii dotyczących uczenia się ludzi i zwierząt jest ściśle powiązanych z pomysłami z nowej dziedziny *uczenia maszynowego*. Uczenie maszynowe to dziedzina na styku statystyki i informatyki, która skupia się na tym, jak budować algorytmy komputerowe, które potrafią uczyć się na podstawie doświadczeń. Chociaż statystyka i uczenie maszynowe często próbują rozwiązywać te same problemy, badacze z tych dziedzin często przyjmują bardzo różne podejścia; słynny statystyk Leo Breiman określił je kiedyś mianem "Dwóch Kultur", aby odzwierciedlić, jak różne mogą być ich podejścia [@breiman2001]. W tej książce postaram się połączyć te dwie kultury, ponieważ oba podejścia dostarczają użytecznych narzędzi do myślenia o danych.

### Aggregation

Another way to think of statistics is as "the science of throwing away data".  In the example of the PURE study above, we took more than 100,000 numbers and condensed them into ten.  It is this kind of *aggregation* that is one of the most important concepts in statistics.  When it was first advanced, this was revolutionary: If we throw out all of the details about every one of the participants, then how can we be sure that we aren't missing something important?

As we will see, statistics provides us ways to characterize the structure of aggregates of data, with theoretical foundations that explain why this usually works well.  However, it's also important to keep in mind that aggregation can go too far, and later we will encounter cases where a summary can provide a very misleading picture of the data being summarized.

### Uncertainty

The world is an uncertain place. We now know that cigarette smoking causes lung cancer, but this causation is probabilistic: A 68-year-old man who smoked two packs a day for the past 50 years and continues to smoke has a 15% (1 out of 7) risk of getting lung cancer, which is much higher than the chance of lung cancer in a nonsmoker. However, it also means that there will be many people who smoke their entire lives and never get lung cancer.  Statistics provides us with the tools to characterize uncertainty, to make decisions under uncertainty, and to make predictions whose uncertainty we can quantify.  

One often sees journalists write that scientific researchers have "proven" some hypothesis.  But statistical analysis can never "prove" a hypothesis, in the sense of demonstrating that it must be true (as one would in a logical or mathematical proof).  Statistics can provide us with evidence, but it's always tentative and subject to the uncertainty that is always present in the real world.

### Sampling from a population

The concept of aggregation implies that we can make useful insights by collapsing across data -- but how much data do we need?  The idea of *sampling* says that we can summarize an entire population based on just a small number of samples from the population, as long as those samples are obtained in the right way.  For example, the PURE study enrolled a sample of about 135,000 people, but its goal was to provide insights about the billions of humans who make up the population from which those people were sampled. As we already discussed above, the way that the study sample is obtained is critical, as it determines how broadly we can generalize the results. Another fundamental insight about sampling is that while larger samples are always better (in terms of their ability to accurately represent the entire population), there are diminishing returns as the sample gets larger. In fact, the rate at which the benefit of larger samples decreases follows a simple mathematical rule, growing as the square root of the sample size, such that in order to double the precision of our estimate we need to quadruple the size of our sample.

## Causality and statistics

The PURE study seemed to provide pretty strong evidence for a positive relationship between eating saturated fat and living longer, but this doesn't tell us what we really want to know: If we eat more saturated fat, will that cause us to live longer? This is because we don't know whether there is a direct causal relationship between eating saturated fat and living longer. The data are consistent with such a relationship, but they are equally consistent with some other factor causing both higher saturated fat and longer life.  For example, one might imagine that people who are richer eat more saturated fat and richer people tend to live longer, but their longer life is not necessarily due to fat intake --- it could instead be due to better health care, reduced psychological stress, better food quality, or many other factors.  The PURE study investigators tried to account for these factors, but we can't be certain that their efforts completely removed the effects of other variables.  The fact that other factors may explain the relationship between saturated fat intake and death is an example of why introductory statistics classes often teach that "correlation does not imply causation", though the renowned data visualization expert Edward Tufte has added, "but it sure is a hint."

Although observational research (like the PURE study) cannot conclusively demonstrate causal relations, we generally think that causation can be demonstrated using studies that experimentally control and manipulate a specific factor.  In medicine, such a study is referred to as a *randomized controlled trial* (RCT). Let's say that we wanted to do an RCT to examine whether increasing saturated fat intake increases life span.  To do this, we would sample a group of people, and then assign them to either a treatment group (which would be told to increase  their saturated fat intake) or a control group (who would be told to keep eating the same as before).  It is essential that we assign the individuals to these groups randomly. Otherwise, people who choose the treatment might be different in some way than people who choose the control group -- for example, they might be more likely to engage in other healthy behaviors as well.  We would then follow the participants over time and see how many people in each group died.  Because we randomized the participants to treatment or control groups, we can be reasonably confident that there are no other differences between the groups that would *confound* the treatment effect; however, we still can't be certain because sometimes randomization yields treatment versus control groups that _do_ vary in some important way.  Researchers often try to address these confounds using statistical analyses, but removing the influence of a confound from the data can be very difficult.

A number of RCTs have examined the question of whether changing saturated fat intake results in better health and longer life.  These trials have focused on *reducing* saturated fat because of the strong dogma amongst nutrition researchers that saturated fat is deadly; most of these researchers would have probably argued that it was not ethical to cause people to eat *more* saturated fat!  However, the RCTs have shown a very consistent pattern: Overall there is no appreciable effect on death rates of reducing saturated fat intake.  



## Learning objectives

Having read this chapter, you should be able to:

* Describe the central goals and fundamental concepts of statistics
* Describe the difference between experimental and observational research with regard to what can be inferred about causality
* Explain how randomization provides the ability to make inferences about causation.

### Agregacja

Innym sposobem myślenia o statystyce jest "nauka o wyrzucaniu danych".  W powyższym przykładzie badania PURE wzięliśmy ponad 100 000 liczb i skondensowaliśmy je do dziesięciu.  To właśnie ten rodzaj *agregacji* jest jednym z najważniejszych pojęć w statystyce.  Kiedy została po raz pierwszy rozwinięta, było to rewolucyjne: Jeśli wyrzucimy wszystkie szczegóły dotyczące każdego z uczestników, to jak możemy być pewni, że nie pomijamy czegoś ważnego?

Jak zobaczymy, statystyka dostarcza nam sposobów na scharakteryzowanie struktury agregatów danych, wraz z teoretycznymi podstawami, które wyjaśniają, dlaczego to zwykle działa dobrze.  Jednak trzeba też pamiętać, że agregacja może pójść za daleko i później spotkamy się z przypadkami, w których podsumowanie może dać bardzo mylący obraz podsumowywanych danych.

### Niepewność

Świat jest miejscem niepewnym. Obecnie wiemy, że palenie papierosów powoduje raka płuc, ale ten związek przyczynowy jest probabilistyczny: 68-letni mężczyzna, który palił dwie paczki dziennie przez ostatnie 50 lat i nadal pali, ma 15% (1 na 7) ryzyko zachorowania na raka płuc, co jest znacznie wyższe niż szansa wystąpienia raka płuc u osoby niepalącej. Oznacza to jednak również, że jest wiele osób, które palą przez całe życie i nigdy nie zachorują na raka płuc.  Statystyka dostarcza nam narzędzi do charakteryzowania niepewności, do podejmowania decyzji w warunkach niepewności oraz do tworzenia prognoz, których niepewność możemy określić ilościowo.  

Często widzi się, jak dziennikarze piszą, że naukowcy "udowodnili" jakąś hipotezę.  Ale analiza statystyczna nigdy nie może "udowodnić" hipotezy, w sensie wykazania, że musi być ona prawdziwa (jak w przypadku dowodu logicznego lub matematycznego).  Statystyka może dostarczyć nam dowodów, ale są one zawsze niepewne i podlegają niepewności, która jest zawsze obecna w świecie rzeczywistym.

### Pobieranie próbek z populacji

Koncepcja agregacji sugeruje, że możemy dokonać użytecznych spostrzeżeń poprzez zestawienie danych - ale ile danych potrzebujemy?  Idea *próbkowania* mówi, że możemy podsumować całą populację na podstawie niewielkiej liczby próbek z populacji, pod warunkiem, że te próbki są uzyskane w odpowiedni sposób.  Na przykład, badanie PURE objęło próbkę około 135 000 osób, ale jego celem było dostarczenie informacji na temat miliardów ludzi, którzy tworzą populację, z której te osoby zostały pobrane. Jak już omówiliśmy powyżej, sposób pozyskania próby badawczej jest krytyczny, ponieważ decyduje o tym, jak szeroko możemy uogólniać wyniki. Innym fundamentalnym spostrzeżeniem dotyczącym doboru próby jest to, że choć większe próby są zawsze lepsze (pod względem możliwości dokładnego reprezentowania całej populacji), to jednak wraz z powiększaniem się próby pojawiają się malejące zyski. W rzeczywistości tempo, w jakim korzyści z większych próbek maleją, jest zgodne z prostą regułą matematyczną, rosnącą jako pierwiastek kwadratowy z wielkości próbki, tak że aby podwoić precyzję naszego oszacowania, musimy czterokrotnie zwiększyć wielkość naszej próbki.

## Przyczynowość i statystyka

Badanie PURE wydawało się dostarczać dość mocnych dowodów na pozytywny związek między spożywaniem tłuszczów nasyconych a dłuższym życiem, ale to nie mówi nam tego, co naprawdę chcemy wiedzieć: Czy jeśli będziemy jeść więcej tłuszczów nasyconych, spowoduje to, że będziemy żyć dłużej? Dzieje się tak dlatego, że nie wiemy, czy istnieje bezpośredni związek przyczynowy pomiędzy spożywaniem tłuszczów nasyconych a dłuższym życiem. Dane są zgodne z takim związkiem, ale są one równie zgodne z jakimś innym czynnikiem powodującym zarówno wyższy poziom tłuszczu nasyconego, jak i dłuższe życie.  Na przykład, można sobie wyobrazić, że ludzie bogatsi jedzą więcej tłuszczów nasyconych i żyją dłużej, ale ich dłuższe życie niekoniecznie wynika ze spożycia tłuszczów --- może to być spowodowane lepszą opieką zdrowotną, zmniejszonym stresem psychologicznym, lepszą jakością żywności lub wieloma innymi czynnikami.  Prowadzący badanie PURE próbowali uwzględnić te czynniki, ale nie możemy być pewni, że ich wysiłki całkowicie usunęły wpływ innych zmiennych.  Fakt, że inne czynniki mogą wyjaśniać związek pomiędzy spożyciem tłuszczów nasyconych a śmiercią jest przykładem tego, dlaczego na zajęciach ze statystyki wstępnej często uczy się, że "korelacja nie implikuje związku przyczynowego", choć znany ekspert od wizualizacji danych Edward Tufte dodał, że "ale na pewno jest to wskazówka".

Chociaż badania obserwacyjne (takie jak badanie PURE) nie mogą niezbicie wykazać związków przyczynowych, generalnie uważamy, że związek przyczynowy można wykazać za pomocą badań, które eksperymentalnie kontrolują i manipulują określonym czynnikiem.  W medycynie takie badanie nazywa się *randomizowaną próbą kontrolowaną* (RCT). Załóżmy, że chcemy przeprowadzić RCT, aby sprawdzić, czy zwiększenie spożycia tłuszczów nasyconych zwiększa długość życia.  W tym celu należy pobrać próbki osób, a następnie przydzielić je do grupy leczonej (której powiemy, żeby zwiększyła spożycie tłuszczów nasyconych) lub grupy kontrolnej (której powiemy, żeby jadła to samo, co wcześniej).  Istotne jest, abyśmy przydzielili osoby do tych grup losowo. W przeciwnym razie osoby, które wybiorą leczenie, mogą być w jakiś sposób inne niż osoby, które wybiorą grupę kontrolną - na przykład mogą być bardziej skłonne do podejmowania innych zdrowych zachowań.  Następnie obserwowaliśmy uczestników w czasie i sprawdzaliśmy, ile osób z każdej grupy zmarło.  Ponieważ randomizowaliśmy uczestników do grup leczonych lub kontrolnych, możemy być w miarę pewni, że nie ma żadnych innych różnic między grupami, które mogłyby *przyczynić się* do efektu leczenia; jednak nadal nie możemy być pewni, ponieważ czasami randomizacja daje grupy leczące i kontrolne, które _różnią się_ w jakiś istotny sposób.  Badacze często próbują zająć się tymi ograniczeniami za pomocą analiz statystycznych, ale usunięcie wpływu ograniczenia z danych może być bardzo trudne.

W wielu badaniach RCT sprawdzano, czy zmiana spożycia tłuszczów nasyconych wpływa na poprawę zdrowia i wydłużenie życia.  Badania te koncentrowały się na *redukcji* tłuszczów nasyconych, ponieważ wśród badaczy zajmujących się żywieniem panuje silny dogmat, że tłuszcze nasycone są śmiertelne; większość z tych badaczy prawdopodobnie twierdziłaby, że nie jest etyczne powodowanie, by ludzie jedli *więcej* tłuszczów nasyconych!  Jednakże, badania RCT wykazały bardzo spójny wzór: Ogólnie rzecz biorąc, nie ma znaczącego efektu na śmiertelność związanego z ograniczeniem spożycia tłuszczów nasyconych.  



## Cele nauczania

Po przeczytaniu tego rozdziału powinieneś być w stanie:

* Opisać centralne cele i podstawowe pojęcia statystyki.
* Opisać różnicę między badaniami eksperymentalnymi i obserwacyjnymi w odniesieniu do tego, co można wnioskować o przyczynowości
* Wyjaśnić, jak randomizacja zapewnia możliwość wnioskowania o przyczynowości.

## Suggested readings

- *The Seven Pillars of Statistical Wisdom*, by Stephen Stigler
- *The Lady Tasting Tea: How Statistics Revolutionized Science in the Twentieth Century*, by David Salsburg
- *Naked Statistics: Stripping the Dread from the Data*, by Charles Wheelan
